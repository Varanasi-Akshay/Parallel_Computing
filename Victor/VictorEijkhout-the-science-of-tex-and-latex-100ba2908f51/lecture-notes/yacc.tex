\Level 0 {Introduction}

The unix utility \yacc\ (Yet Another Compiler Compiler) parses a
stream of token, typically generated by \lex, according to a
user-specified grammar.

\Level 0 {Structure of a \yacc\ file}

A \yacc\ file looks much like a \lex\ file:
\begin{verbatim}
  ...definitions...
%%
  ...rules...
%%
  ...code...
\end{verbatim}

\begin{description}
\item[definitions] As with \lex, all code between \verb+%{+ and \verb+%}+
 is copied to the beginning of the resulting C file. There can also be
 various definitions; see section~\ref{yacc:def}.
\item[rules] As with \lex, a~number of combinations of pattern and
  action. The patterns are now those of a context-free grammar, rather
  than of a regular grammar as was the case with~\lex.
\item[code] This can be very elaborate, but the main ingredient is the
  call to \n{yyparse}, the grammatical parse.
\end{description}

\Level 0 {Motivating example}

It is harder to give a small example of \yacc\ programming than it was
for~\lex. Here is a program that counts the number of \emph{different}
words in a text. (We could have written this particular example in
\lex\ too.)

First consider the \lex\ program that matches words:
\verbatiminput{words-lex.l}
The lexer now no longer has a main program, but instead returns a
\n{WORD} return code. It also calls a routine \n{find_word}, which
inserts the matched word in a list if it is not already there.

The routine \n{find_word} is defined in the \yacc\ code:
\verbatiminput{words.y}
Other things to note:
\begin{itemize}
\item The \n{WORD} token that was used in the \lex\ code is defined
  here in the definitions section; \lex\ knows about it through
  including the \n{words.h} file.
\item The \lex\ rule also sets a variable \n{yylval}; this puts a
  value on the stack top, where \yacc\ can find it with
  \n{\$1},~\n{\$2}, et cetera.
\end{itemize}
All of this will be explained in detail below.

\Level 0 {Definitions section}
\label{yacc:def}

There are three things that can go in the definitions section:
\begin{description}
\item[C code] Any code between \verb+%{+ and \verb+%}+
  is copied to the C file. This is typically used for defining file
  variables, and for prototypes of routines that are defined in the
  code segment.
\item[definitions] The definitions section of a \lex\ file was
  concerned with characters; in \yacc\ this is tokens. These token
  definitions are written to a~\n{.h} file when \yacc\ compiles this file.
\item[associativity rules] These handle associativity and priority of
  operators; see section~\ref{yacc:ops}.
\end{description}

\Level 0 {Lex \ Yacc interaction}

Conceptually, \lex\ parses a file of characters and outputs a stream
of tokens; \yacc\ accepts a stream of tokens and parses it, performing
actions as appropriate. In practice, they are more tightly coupled.

If your \lex\ program is supplying a tokenizer, the \yacc\ program
will repeatedly call the \n{yylex} routine. The \lex\ rules will
probably function by calling \n{return} every time they have
parsed a token. We will now see the way \lex\ returns information in
such a way that \yacc\ can use it for parsing.

\Level 1 {The shared header file of return codes}
\label{sec:returncode}

If \lex\ is to return tokens that \yacc\ will process, they have to
agree on what tokens there are. This is done as follows.
\begin{itemize}
\item The \yacc\ file will have token definitions
\begin{verbatim}
%token NUMBER
\end{verbatim}
in the definitions section.
\item When the \yacc\ file is translated with \n{yacc -d -o}, a header
  file \n{<file>.h}\footnote{If you leave out the \n{-o} option to
    \yacc, the file is called \n{y.tab.h}.} is created that has
  definitions like
\begin{verbatim}
#define NUMBER 258
\end{verbatim}
This file can then be included in both the \lex\ and \yacc\ program.
\item The \lex\ file can then call \n{return NUMBER}, and the
  \yacc\ program can match on this token.
\end{itemize}

The return codes that are defined from \verb+%TOKEN+ definitions typically
start at around~258, so that single characters can simply be returned
as their integer value:
\begin{verbatim}
/* in the lex program */
[0-9]+ {return NUMBER}
[-+*/] {return *yytext}

/* in the yacc program */
sum : NUMBER '+' NUMBER
\end{verbatim}
The \yacc\ code now recognizes a \n{sum} if \lex\ returns in sequence
a \n{NUMBER} token, a plus character, and another \n{NUMBER} token.

See example~\ref{ex:calc1} for a worked out code.

\Level 1 {Return values}

In the above, very sketchy example, \lex\ only returned the
information that there was a number, not the actual number. For this
we need a further mechanism. In addition to specifying the return
code, the \lex\ parser can return a value that is put on top of the
stack, so that \yacc\ can access it. This symbol is returned in the
variable \n{yylval}. By default, this is defined as an \n{int}, so the
\lex\ program would have
\begin{verbatim}
extern int yylval;
%%
[0-9]+ {yylval=atoi(yytext); return NUMBER;}
\end{verbatim}
See section~\ref{yacc:rule-rhs} for how the stack values are used
by~\yacc.

If more than just integers need to be returned, the specifications in
the \yacc\ code become more complicated. Suppose we are writing a
calculator with variables, so we want to return
double values, and integer indices in a table. The following three
actions are needed.
\begin{enumerate}
\item The possible return values need to be stated:
\begin{verbatim}
%union {int ival; double dval;}
\end{verbatim}
\item These types need to be connected to the possible return tokens:
\begin{verbatim}
%token <ival> INDEX
%token <dval> NUMBER
\end{verbatim}
\item The types of non-terminals need to be given:
\begin{verbatim}
%type <dval> expr
%type <dval> mulex
%type <dval> term
\end{verbatim}
\end{enumerate}

The generated \n{.h}~file will now have
\begin{verbatim}
#define INDEX 258
#define NUMBER 259
typedef union {int ival; double dval;} YYSTYPE;
extern YYSTYPE yylval;
\end{verbatim}

This is illustrated in example~\ref{ex:calc2}.

\Level 0 {Rules section}

The rules section contains the grammar of the language you want to
parse. This looks like
\begin{verbatim}
name1 :   THING something OTHERTHING {action}
        | othersomething THING       {other action}
name2 :   .....
\end{verbatim}
This is the general form of context-free grammars, with a set of
actions associated with each matching right-hand side. It is a good
convention to keep non-terminals (names that can be expanded further)
in lower case and terminals (the symbols that are finally matched) in
upper case.

The terminal symbols get matched with return codes from the
\lex\ tokenizer. They are typically defines coming from \verb+%token+
definitions in the \yacc\ program or character values; see
section~\ref{sec:returncode}.

A simple example illustrating the ideas in this section can be found in
section~\ref{ex:calc1}.

\Level 1 {Rule actions}
\label{yacc:rule-rhs}

The example in section~\ref{ex:calc1} had such rules as:
\begin{verbatim}
expr:
        expr '+' mulex      { $$ = $1 + $3; }
        | expr '-' mulex    { $$ = $1 - $3; }
        | mulex             { $$ = $1; }
\end{verbatim}
The action belonging to the different right hand sides refer to
\n{\$}$n$ quantities and to \n{\$\$}. The latter refers to the stack
top, so by assigning to it a new item is put on the stack top. The former
variables are assigned the values on the top of the stack: if the
right hand side has three terms, terminal or nonterminal, then \n{\$1}
through \n{\$3} are assigned and the three values are removed from the
stack top.

\Level 0 {Operators; precedence and associativity}
\label{yacc:ops}

The example in section~\ref{ex:calc1} had separate rules for
addition/subtraction and multiplication/division. We could simplify
the grammar by writing
\begin{verbatim}
expr:
        expr '+' expr ;
        expr '-' expr ;
        expr '*' expr ;
        expr '/' expr ;
        expr '^' expr ;
        number ;
\end{verbatim}
but this would have \n{1+2*3} evaluate to~9. In order to indicate
operator precedence, we can have lines
\begin{verbatim}
%left '+' '-'
%left '*' '/'
%right '^'
\end{verbatim}
The sequence of lines indicates increasing operator precedence and the
keyword sets the associativity type: we want \n{5-1-2} to be~2, so
minus is left associative; we want \n{2^2^3} to be~256, not~64, so
exponentiation is right associative.

Operators that can be both unary and binary are handled by declaring a
non-associative token, and explicitly indicating its precedence.
\begin{verbatim}
%left '-' '+'
%nonassoc UMINUS
%
expression : expression '+' expression
    | expression '-' expression
    | '-' expression %prec UMINUS
\end{verbatim}

\Level 0 {Further remarks}

\Level 1 {User code section}

The minimal main program is
\begin{verbatim}
int main()
{
  yyparse();
  return 0;
}
\end{verbatim}
Extensions to more ambitious programs should be self-evident.

In addition to the main program, the code section will usually also
contain subroutines, to be used either in the \yacc\ or the
\lex\ program. See for instance example~\ref{ex:calc3}.

\begin{594exercise}
Try to write \lex\ or \yacc\ programs for the following languages:
\[ a^nb^m, \quad a^nb^n, \quad a^nb^nc^n \]
Discuss the theoretical power of \lex\ and \yacc.
\end{594exercise}
\begin{answer}
First we observe that through the inclusion of C~code, all these
languages, whether regular, context-free, context-sensitive, can be
parsed in \lex. This means that \lex\ and \yacc\ are theoretically not
restricted to regular and context-free languages, even though their
basic mechanism is a FSA and PDA respectively.

Let us now look at solutions that use both \lex\ and \yacc.

For these languages, the \lex\ program can be very simple:
\verbatiminput{anbn-lex.l}
The problem with the \yacc\ code is how to give error messages for
ungrammatical strings. This program recognizes the language, and lets
\yacc\ give its default error on ungrammatical strings:
\verbatiminput{anbn1.y}
Attempts to parse unbalanced strings of $a$s and $b$s such as
\verbatiminput{anbn2.y}
invariably lead to conflicts, because \yacc\ can not decide which rule
to match on an $a$~input. An unbalanced amounts of $b$s can be
handled:
\verbatiminput{anbn3.y}
but for a general solution we really need to recognize~$\{a^mb^n\}$
and impose the restriction~$m\equiv\nobreak n$ through included
C~code:
\verbatiminput{anbn4.y}
Without the error clauses, this recognizes $a^mb^n$, and it is easy to
extend this program to~$a^nb^nc^n$.
\end{answer}

\Level 1 {Errors and tracing}

So far we have assumed that the input to \yacc\ is syntactically
correct, and \yacc\ need only discover its structure. However,
occasionally input will be incorrect.

\Level 2 {Tracing}

If you assign \verb+yydebug=1;+, \yacc\ will produce trace
output. While its states may not make sense to you, at least you will
see which tokens it matches, and which rules it can reduce.

\Level 2 {Syntax errors}

Sometimes, \yacc\ reports `\n{syntax error}' and stops
processing. This means that an unexpected symbol is found.  A~common
source for this is the case that you have made a typo in your grammar,
and the symbol it is trying to match is not defined. Example: suppose
we have just matched an open token:
\begin{verbatim}
group : open body close
bodytext : ;
        | character bodytext
\end{verbatim}
If you are tracing \yacc's workings, you will probably see it matching
the \n{character}, then giving the \n{syntax error} message.

The `syntax error' message is actually \yacc's default implementation
of the \index{yyerror}\n{yyerror} routine, but it can be redefined at
will. For example, suppose we have a declaration
\begin{verbatim}
int lineno=1;      /* in yacc */
extern int lineno; /* in lex */
\end{verbatim}
and every line with \verb+\n+ in \lex\ increases this variable. We
could then define
\begin{verbatim}
void yyerror(char *s)
{
  printf("Parsing failed in line %d because of %s\n",
         lineno,s);
}
\end{verbatim}

\Level 2 {Error recovery}

Error recovery in \yacc\ is possible through the \n{error} token. In
the rule
\begin{verbatim}
foo : bar baz ;
    | error baz printf("Hope for the best\n");
\end{verbatim}
recognizing any token but \n{bar} will make \yacc\ start skipping
tokens, hoping to find \n{baz} and recover from that point.
This is not guaranteed to work.

\Level 2 {Semantical errors}

Both \lex\ and \yacc\ are stronger than simple finite-state or
pushdown automata, for instance if they are endowed with a symbol
table. This can be used to detect semantic errors. For instance, while
you would like to write
\begin{verbatim}
array_slice : array_name '[' int_expr ']'
\end{verbatim}
you may be limited to
\begin{verbatim}
array_slice : ident '[' int_expr ']'
                {if (!is_array($1)) { ....
\end{verbatim}
There are a couple of tools here:
\begin{description}
\item[\n{yyerror(char*)}] is a default write to \n{stderr}; you can
  redefine it.
\item[\n{YYABORT}] is a macro that halts parsing.
\end{description}

\Level 1 {Makefile rules for \yacc}

The \n{make} utility knows about \lex\ and \yacc, but if you want to
do things yourself, here are some good rules:
\begin{verbatim}
# disable normal rules
.SUFFIXES:
.SUFFIXES: .l .y .o

# lex rules
.l.o :
        lex -t $*.l > $*.c
        cc -c $*.c -o $*.o

# yacc rules
.y.o :
        if [ ! -f $*.h ] ; then touch $*.h ; fi
        yacc -d -t -o $*.c $*.y 
        cc -c -o $*.o $*.c ;
        rm $*.c

# link lines
lexprogram : $(LEXFILE).o
        cc $(LEXFILE).o -o $(LEXFILE) -ll
yaccprogram : $(YACCFILE).o $(LEXFILE).o
        cc $(YACCFILE).o $(LEXFILE).o -o $(YACCFILE) -ly -ll
\end{verbatim}

\Level 1 {The power of \yacc}

Theoretically, \yacc\ implements an LALR(1) parser, which is
essentially an $LR$ parser with one token look-ahead. This describes a
large class of useful grammars. As an example of a grammar with
\emph{two} tokens look-ahead, consider
\begin{bnf}
phrase: CART\_ANIMAL and cart; WORK\_ANIMAL and plow.
CART\_ANIMAL: horse; goat.
WORK\_ANIMAL: horse; ex.
\end{bnf}
Now to distinguish between \n{horse and cart} and \n{horse and plow}
from the word \n{horse} takes two tokens look-ahead.

\begin{594exercise}
Use the \TeX\ parser you wrote in \lex\ to parse
\LaTeX\ documents. The parser should 
\begin{itemize}
\item Report the documentclass used;
\item Check that \verb+\begin{document}+ and \verb+\end{document}+ are
  used, with no text before the begin command;
\item Know about some commands with one argument, such as~\cs{textbf},
  and properly recognize that argument
\item Recognize proper matching of begin/end of an environment.
\end{itemize}
Bonus: let your parser interpret \cs{newcommand} correctly. You can
limit yourself to the the case of commands with one argument, that is
\begin{verbatim}
\newcommand{\foo}[1]{ ...}
\end{verbatim}
\end{594exercise}
\begin{answer}
\verbatiminput{tex1.y}
\end{answer}

\Level 0 {Examples}

\Level 1 {Simple calculator}
\label{ex:calc1}

This calculator evaluates simple arithmetic expressions. The
\lex\ program matches numbers and operators and returns them; it
ignores white space, returns newlines, and gives an error message on
anything else.
\verbatiminput{calc1-lex.l}
Accepting the \lex\ output, the following \yacc\ program has rules that parse
the stream of numbers and operators, and perform the corresponding
calculations.
\verbatiminput{calc1.y}
Here we have realized operator precedence by having separate rules for
the different priorities. The rule for plus/minus comes first, which
means that its terms, the \n{mulex} expressions involving
multiplication, are evaluated first.

\Level 1 {Calculator with simple variables}
\label{ex:calc2}

In this example the return variables have been declared of type
double. Furthermore, there can now be single-character variables that
can be assigned and used. There now are two different return tokens:
double values and integer variable indices.
This necessitates the \verb+%union+ statement, as well as
\verb+%token+ statements for the various return tokens and
\verb+%type+ statements for the non-terminals.

This is all in the \yacc\ file:
\verbatiminput{calc2.y}
The \lex\ file is not all that different; note how return values are
now assigned to a component of \n{yylval} rather than \n{yylval}
itself.
\verbatiminput{calc2-lex.l}

\Level 1 {Calculator with dynamic variables}
\label{ex:calc3}

Basically the same as the previous example, but now variable names can
have regular names, and they are inserted into a names table
dynamically. The \yacc\ file defines a routine for getting a variable
index:
\verbatiminput{calc3.y}
The \lex\ file is largely unchanged, except for the rule that
recognises variable names:
\verbatiminput{calc3-lex.l}
